# resources/employee_master_job.yml
resources:
  jobs:
    employee_master_job:
      name: employee_master_job_${var.environment}
      
      tasks:
        - task_key: cleanup_bronze_task
          notebook_task:
            notebook_path: ${var.notebook_base_path}/cleanupBronze
            base_parameters:
              storage_account_name: ${var.storage_account_name}
              container_name: ${var.container_name}
              environment: ${var.environment}
            source: WORKSPACE
          job_cluster_key: Job_cluster
        
        - task_key: process_employee_data
          depends_on:
            - task_key: cleanup_bronze_task
          notebook_task:
            notebook_path: ${var.notebook_base_path}/employeeRaw2Bronze
            base_parameters:
              storage_account_name: ${var.storage_account_name}
              container_name: ${var.container_name}
              environment: ${var.environment}
            source: WORKSPACE
          job_cluster_key: Job_cluster
      
      job_clusters:
        - job_cluster_key: Job_cluster
          new_cluster:
            cluster_name: ""
            spark_version: 16.4.x-scala2.12
            azure_attributes:
              first_on_demand: 1
              availability: SPOT_WITH_FALLBACK_AZURE
              spot_bid_max_price: -1
            node_type_id: ${var.cluster_node_type}
            spark_env_vars:
              PYSPARK_PYTHON: /databricks/python3/bin/python3
            enable_elastic_disk: true
            data_security_mode: LEGACY_SINGLE_USER_STANDARD
            runtime_engine: PHOTON
            num_workers: ${var.num_workers}
    
      queue:
        enabled: true
      
      tags:
        environment: ${var.environment}
        
      
      queue:
        enabled: true
      
      tags:
        environment: ${var.environment}