trigger:
- main

pool:
  vmImage: ubuntu-latest

variables:
- group: databricks-stage         # has: databricks-host, databricks-token
- name: SRC_NOTEBOOKS_DIR
  value: notebook                 # folder in your repo (adjust if different)
- name: DEST_WORKSPACE_DIR
  value: /Shared/deploy/notebooks # where to copy in STAGING workspace

steps:
- checkout: self
  fetchDepth: 0

- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.10'

- script: |
    python -m pip install --upgrade pip
    pip install --upgrade databricks-cli
    databricks --version
  displayName: Install Databricks CLI (legacy)

- script: |
    set -e
    echo "Using host: $(databricks-host)"
    export DATABRICKS_HOST="$(databricks-host)"
    export DATABRICKS_TOKEN="$(databricks-token)"

    echo "Listing / before import"
    databricks workspace ls /

    echo "Ensuring destination: $(DEST_WORKSPACE_DIR)"
    databricks workspace mkdirs "$(DEST_WORKSPACE_DIR)"

    echo "Importing from repo folder: $(SRC_NOTEBOOKS_DIR)"
    databricks workspace import_dir --overwrite "$(SRC_NOTEBOOKS_DIR)" "$(DEST_WORKSPACE_DIR)"

    echo "Listing destination after import"
    databricks workspace ls "$(DEST_WORKSPACE_DIR)"
  displayName: Import notebooks to STAGING
