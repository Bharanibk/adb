trigger:
- main

pool:
  vmImage: ubuntu-latest

variables:
- group: databricks-stage     # contains: databricks-host, databricks-token

steps:
- checkout: self
  fetchDepth: 0

- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.10'

# Install NEW Databricks CLI (Go) - pinned release
- script: |
    set -e
    sudo apt-get update -y
    sudo apt-get install -y unzip
    mkdir -p $HOME/.databricks/bin
    curl -L https://github.com/databricks/cli/releases/download/v0.224.0/databricks_linux_amd64.zip -o /tmp/databricks_cli.zip
    unzip -o /tmp/databricks_cli.zip -d $HOME/.databricks/bin
    chmod +x $HOME/.databricks/bin/databricks
    echo '##vso[task.prependpath]'$HOME'/.databricks/bin'
    databricks version
  displayName: Install Databricks CLI (v0.224.0)

# Validate the bundle against STAGE
- script: |
    set -e
    export DATABRICKS_HOST="$(databricks-host)"
    export DATABRICKS_TOKEN="$(databricks-token)"
    cd bundle
    databricks bundle validate -t stage
  displayName: Validate bundle (-t stage)

# Deploy notebooks + job to STAGE
- script: |
    set -e
    export DATABRICKS_HOST="$(databricks-host)"
    export DATABRICKS_TOKEN="$(databricks-token)"
    cd bundle
    databricks bundle deploy -t stage
  displayName: Deploy bundle (-t stage)

# Optional: run the job once after deploy
- script: |
    set -e
    export DATABRICKS_HOST="$(databricks-host)"
    export DATABRICKS_TOKEN="$(databricks-token)"
    cd bundle
    databricks bundle run employee_master_job -t stage --refresh-all
  displayName: Run employee_master_job (stage)
